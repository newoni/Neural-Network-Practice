List of files

1. practice01.py
  page 20
  Feature scaling. 
    - sklearn 모듈의 preprocessing 사용

2. practice02.py
  page 21
  Keras Feature engineering 
    - keras 모듈의 ImageDataGenerator 사용
    - 이미지 부풀리기
    
3. practice03.py
  page 23
  Supervised learning algorithms
     - sklearn의 LinearRegreesion 사용
     - sklearndml.metrics의 meansquared_error 사용

4. pratice04.py
  page 25
  Evaluating the model
    - sklearn의 train_test_split
    - scaling 이후, Linear Regression.
    - practice03과 다른점. train_test_split 사용. (practice03은 수동으로 나누어줌)

5. practice05.py
  page 32
  Implementing a perceptron
    - DataFrame, np.random.randn, pd.concat 으로 가상 데이터 분포 만들기.
    - seaborn.scatterplot 사용
    - 기본 perceptron numpy 구현

6. practice06.py
  page 39
  Implementing perceptron in keras
    - practice05.py 와 같은 데이터
    - keras로 practice05.py 구현
    - sklearn.metrics의 roc_auc_score 사용.

7. practice07.py
  page 49
  Keras Implementation
    - 간단한 Keras 

8. practice08.py
  page 52
  The XOR problem
    - XOR data problem data 생성
    - matplotlib.pyplot의 scatter 사용(alpha)
    - matplotlib.pyplot의 colorbar 

9. practice09.py
  page 54
  FFNN in python from scratch
    - practice08.py 와 같은 데이터 생성
    - 결과물이 만족스럽지 않음.
    - FFNN class 만들어서 propagation, back propagation 구현
    - 내 생각에, hidden size가 layer 수가 2개가 아니라, 1개의 hidden layer에 neuron 수가 2개임.
    - 출력 layer 수도 이상함. (2가 아니라, 1이 맞다고 생각)
    - 차후 수정 하기.
    - confusion maxtrix 이용.(from sklearn.metrics import confusion_matrix)
    - 이외의 metrics로 MSE(mean squared error), AUC(roc auc score) 활용

10. practice10.py
  page 58
   FFNN Keras implementaion
    - practice08.py와 같은 데이터 생성
    - 마찬가지로 hidden layer가 하나만 있다고 판단되
    - Dense를 하나 더 추가하면 결과가 더 만족스러움
    - MSE 의미를 더 잘 생각해보기, 결과값 출력을 더 깔끔하게 할 수 있는 방법 생각해보기
